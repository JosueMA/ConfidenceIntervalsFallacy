In a classic paper, @Neyman:1937 laid the formal foundation for confidence intervals. It is easy to describe the practical problem that Neyman saw CIs as solving. Suppose a researcher is interested in estimating a parameter $\theta$. Neyman suggests that researchers perform the following three steps:

1.  Perform an experiment, collecting the relevant data.
2.  Compute two numbers &mdash; the smaller of which we can call $L$, the greater $U$ &mdash; forming an interval $(L,U)$ according to a specified procedure.
3.  State that $L<\theta<U$ &mdash; that is, that $\theta$ is in the interval.

This recommendation is justified by choosing an procedure for step (1) such that in the long run, the researcher's claim in step (2) will be correct, on average, $X\%$ of the time. A confidence interval is any interval computed using such a procedure. 

We first focus on the meaning of the statement that $\theta$ is in the interval, in step (3). As we have seen, according to CI theory, what happens in step (3) is not a belief, a conclusion, or any sort of reasoning from the data. Furthermore, it is not associated with any level of uncertainty about whether $\theta$ is, actually, in the interval. It is merely a dichotomous statement that is meant to have a specified probability of being true in the long run. 

Frequentist evaluation of confidence procedures is based on what can be called the "power" of the procedures, which is the frequency with which false values of a parameter are excluded.  Better intervals are shorter on average, excluding false values more often [@Lehmann:1959;@Neyman:1937;@Neyman:1941;@Welch:1939]. Consider a particular false value of the parameter, $\theta'\neq\theta$. Different confidence procedures will exclude that false value at different rates. If some confidence procedure CP $A$ excludes $\theta'$, on average, more often than some CP $B$, then CP $A$ is better than CP $B$ for that value. 

Sometimes we find that one CP excludes *every* false value at a rate greater than some other CP; in this case, the first CP is uniformly more powerful than the second. There may even be a "best" CP: one that excludes every false $\theta'$ value at a rate greater than any other possible CP. This is analogous to a most-powerful test. Although a best confidence procedure does not always exist, we can always compare one procedure to another to decide whether one is better in this way [@Neyman:1952]. Confidence procedures are therefore closely related to hypothesis tests: confidence procedures control the rate of including the true value, and better confidence procedures have more power to exclude false values.



